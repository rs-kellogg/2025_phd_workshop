{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7135220",
   "metadata": {},
   "source": [
    "#  LLM Testing \n",
    "\n",
    "## LLM Testing List\n",
    "![llm_scheme](images/llm_scheme.png)\n",
    "- Structure & Formatting\n",
    "  * Length control: Ensure response respect token limits.\n",
    "  * Output structure enforcement: Validate that responses follow required formats (e.g., bullet points, tables, JSON).\n",
    "\n",
    "- Consistency & Stability\n",
    "  * Reproducibility: Set temperature and seed value.\n",
    "  * Prompt sensitivity: Assess how changes in wording affect results.\n",
    "  * Regression testing: Detect output changes over model versions.\n",
    "\n",
    "- Correctness: Check against expected answers or external source (exact match or similarity)\n",
    "\n",
    "\n",
    "## Check Correctness\n",
    "![test_scheme](./images/testing_scheme_v2.png)\n",
    "\n",
    "- Generate a Golden Set\n",
    "  * Manually curate a reference (golden) dataset\n",
    "  * Develop a function to extract reference data from a database\n",
    "- Comparison Techniques\n",
    "  * **Exact Match**: Direct match for labels like True/False, multiple choice (A/B/C/D), or numeric values\n",
    "  * **Partial Match**: Verify presence of key phrases within the response\n",
    "  * **Semantic Similarity**: Compute cosine similarity between embedding vectors to assess meaning-based closeness\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88b4c6a",
   "metadata": {},
   "source": [
    "## Lab 1\n",
    "\n",
    "## Lab 2: Extract infrmation from earning report\n",
    "* Defines a \"golden set\" of expected phrases (like unit test assertions).\n",
    "* Checks that the LLM includes all critical facts.\n",
    "* Gives a clean pass/fail result with explanation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be615e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_summary_quality(output: str, expected_phrases: List[str]) -> bool:\n",
    "    \"\"\"Unit-style test: check if all expected phrases appear in the output.\"\"\"\n",
    "    output = output.lower()\n",
    "    expected_phrases = [phrase.lower() for phrase in expected_phrases]\n",
    "    missing = [phrase for phrase in expected_phrases if phrase not in output]\n",
    "    if missing:\n",
    "        print(\"=== Test failed. Missing key points:\")\n",
    "        for m in missing:\n",
    "            print(f\" - {m}\")\n",
    "        return False\n",
    "    print(\"=== Test passed. Output contains all expected key points.\")\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b5519ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged interaction to logs/logfile_2025-07-03.jsonl\n",
      "\n",
      "=== LLM Output:\n",
      " Q1 2024 Earnings Summary for Internal Strategy Briefing:\n",
      "\n",
      "**Revenue:**  \n",
      "Starbucks generated $9.4 billion in consolidated net revenues, representing an 8% year-over-year growth. The North America segment contributed a 9% revenue increase, driven by higher average tickets and increased store traffic. International revenues grew by 7%, with China exhibiting particularly strong performance, evidenced by an 11% increase in same-store sales.\n",
      "\n",
      "**Profit:**  \n",
      "Net income rose to $1.1 billion, translating to $0.78 per share, up from $0.68 per share in Q1 2023. Operating margin improved by 40 basis points YoY, reflecting operational efficiencies and favorable sales mix.\n",
      "\n",
      "**Growth Drivers:**  \n",
      "Key growth drivers include continued investment in digital platforms and mobile ordering, which enhance customer engagement and convenience. The company’s global store expansion—adding 549 new stores—also supports revenue growth and market penetration.\n",
      "\n",
      "**Geographic Performance:**  \n",
      "- **North America:** Strong performance with a 9% revenue increase driven by higher traffic and ticket size.  \n",
      "- **International:** 7% revenue growth, with China leading the international segment, posting an 11% increase in same-store sales.\n",
      "\n",
      "**Outlook:**  \n",
      "Starbucks reaffirmed its full-year guidance, expecting high-single-digit revenue growth for FY2024.\n",
      "\n",
      "=== Running Unit Test...\n",
      "\n",
      "=== Test passed. Output contains all expected key points.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# --- Realistic business prompt for LLM ---\n",
    "test_prompt = \"\"\"\n",
    "Summarize the following Q1 2024 earnings report for internal strategy briefings. Focus on revenue, profit, growth drivers, and geographic performance:\n",
    "\n",
    "'In its first quarter of fiscal 2024, Starbucks reported consolidated net revenues of $9.4 billion, representing an 8% increase over the prior year. Net income grew to $1.1 billion, or $0.78 per share, compared to $0.68 per share in Q1 2023. The North America segment saw a 9% revenue increase, fueled by higher average ticket and increased store traffic. International revenue rose 7%, with particularly strong performance in China where same-store sales jumped 11%. Starbucks opened 549 new stores globally in the quarter, bringing its total to over 38,000. CEO Laxman Narasimhan cited continued investment in digital platforms and mobile ordering as a key competitive advantage. Operating margin expanded 40 basis points year-over-year. The company reaffirmed its full-year guidance of high-single-digit revenue growth.'\n",
    "\"\"\"\n",
    "\n",
    "# --- Define expected content for unit test ---\n",
    "expected_phrases = [\n",
    "    \"$9.4 billion\",\n",
    "    \"$1.1 billion\",\n",
    "    \"North America\",\n",
    "    \"China\",\n",
    "    # \"549 new stores\",\n",
    "    # \"digital platforms and mobile ordering\",\n",
    "    # \"operating margin\"\n",
    "]\n",
    "\n",
    "# --- Run the test ---\n",
    "llm_model = \"gpt-4.1-nano\"\n",
    "temperature = 0.7\n",
    "max_tokens = 1000\n",
    "output = llm_with_logging(test_prompt, llm_model, llm_openai,temperature, max_tokens)\n",
    "print(\"\\n=== LLM Output:\\n\", output)\n",
    "print(\"\\n=== Running Unit Test...\\n\")\n",
    "test_summary_quality(output, expected_phrases)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0704550",
   "metadata": {},
   "source": [
    "### Case 2: Generate marketing materials\n",
    "\n",
    "* Track changes in model output over time or when prompts/models change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e31f907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged interaction to logs/logfile_2025-07-03.jsonl\n",
      "\n",
      "=== LLM Output:\n",
      " Unlock Your Adventure: Earn Travel Perks, Cash Back, and No Annual Fee with Our New Rewards Credit Card!\n",
      "=== Test passed. Output contains all expected key points.\n",
      "Logged interaction to logs/logfile_2025-07-03.jsonl\n",
      "\n",
      "=== LLM Output:\n",
      " \"Unlock Your Next Adventure: Introducing the Ultimate Rewards Credit Card for Young Professionals - Enjoy Travel Perks, Cash Back, and No Annual Fee!\"\n",
      "=== Test passed. Output contains all expected key points.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_prompt = \"\"\"Write a compelling headline for an email marketing campaign promoting a new rewards credit card for young professionals. Focus on travel perks, no annual fee, and cash back.\"\"\"\n",
    "\n",
    "expected_phrases = [\"travel\", \"no annual fee\", \"cash back\"]\n",
    "\n",
    "# Run on two model versions\n",
    "llm_model = \"gpt-4.1-nano\"\n",
    "temperature = 0.7\n",
    "max_tokens = 1000\n",
    "output = llm_with_logging(test_prompt, llm_model, llm_openai, temperature, max_tokens)\n",
    "print(\"\\n=== LLM Output:\\n\", output)\n",
    "test_summary_quality(output, expected_phrases)\n",
    "\n",
    "llm_model = \"gpt-3.5-turbo\"\n",
    "output = llm_with_logging(test_prompt, llm_model, llm_openai, temperature, max_tokens)\n",
    "print(\"\\n=== LLM Output:\\n\", output)\n",
    "test_summary_quality(output, expected_phrases)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcba843",
   "metadata": {},
   "source": [
    "### Case 3: Check classification outcome\n",
    "\n",
    "* Adopt embedding to compare similarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12e2ec8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from openai import OpenAI\n",
    "def get_embedding_openai(text):\n",
    "    \"\"\"\n",
    "    Get embedding vector for a category string using OpenAI embeddings API.\n",
    "    \"\"\"\n",
    "    api_key = Path(\"./openai.key\").read_text().strip()\n",
    "    client = OpenAI(api_key=api_key)\n",
    "\n",
    "    # Use a small model for speed/cost; adjust as needed\n",
    "    response = client.embeddings.create(\n",
    "        input=text,\n",
    "        model=\"text-embedding-3-small\"\n",
    "    )\n",
    "\n",
    "    return response.data[0].embedding\n",
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    \"\"\"\n",
    "    Compute cosine similarity between two vectors.\n",
    "    \"\"\"\n",
    "    v1 = np.array(vec1)\n",
    "    v2 = np.array(vec2)\n",
    "    return float(np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc2953a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "#  Evaluation Function\n",
    "def evaluate_product_classification(df, llm_model, prompt, temperature, max_tokens):\n",
    "    \"\"\"\n",
    "    Send each product name to LLM and compare output category to golden label.\n",
    "    Adds columns for LLM response, predicted category, match status, and error type.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        product = row[\"product_name\"]\n",
    "        gold_category = row[\"ground_truth_category\"]\n",
    "\n",
    "        user_prompt = f\"{prompt} {product}\\n\"\n",
    "\n",
    "        llm_output = llm_with_logging(user_prompt, llm_model, llm_openai, temperature, max_tokens)\n",
    "\n",
    "        # Try to extract category from LLM output\n",
    "        category_match = re.search(r\"Category:\\s*(.*)\", llm_output)\n",
    "        predicted_category = category_match.group(1).strip().lower() if category_match else \"N/A\"\n",
    "\n",
    "        match = predicted_category == gold_category.lower()\n",
    "\n",
    "        # Get embeddings and similarity\n",
    "        pred_emb = get_embedding_openai(predicted_category)\n",
    "        gold_emb = get_embedding_openai(gold_category)\n",
    "        similarity = cosine_similarity(pred_emb, gold_emb)\n",
    "\n",
    "        results.append({\n",
    "            \"product_name\": product,\n",
    "            \"gold_category\": gold_category,\n",
    "            \"llm_response\": llm_output,\n",
    "            \"predicted_category\": predicted_category,\n",
    "            \"match\": match,\n",
    "            \"error_type\": \"\" if match else \"misclassification\",\n",
    "            \"cosine_similarity\": similarity\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2de0f074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged interaction to logs/logfile_2025-07-03.jsonl\n",
      "Logged interaction to logs/logfile_2025-07-03.jsonl\n",
      "Logged interaction to logs/logfile_2025-07-03.jsonl\n",
      "Logged interaction to logs/logfile_2025-07-03.jsonl\n",
      "Logged interaction to logs/logfile_2025-07-03.jsonl\n",
      "Logged interaction to logs/logfile_2025-07-03.jsonl\n",
      "Logged interaction to logs/logfile_2025-07-03.jsonl\n",
      "Logged interaction to logs/logfile_2025-07-03.jsonl\n",
      "Logged interaction to logs/logfile_2025-07-03.jsonl\n",
      "Logged interaction to logs/logfile_2025-07-03.jsonl\n"
     ]
    }
   ],
   "source": [
    "df_products = pd.DataFrame({\n",
    "    \"product_name\": [\n",
    "        \"Dyson V11 Torque Drive\",\n",
    "        \"Keurig K-Supreme Plus SMART\",\n",
    "        \"iPhone 15 Pro Max\",\n",
    "        \"YETI Rambler 20 oz Tumbler\",\n",
    "        \"Sony WH-1000XM5\",\n",
    "        \"Blue Diamond Almonds - Lightly Salted\",\n",
    "        \"Peloton Bike+\",\n",
    "        \"Nest Thermostat (3rd Gen)\",\n",
    "        \"L'Oréal Paris Revitalift Serum\",\n",
    "        \"Kindle Paperwhite Signature Edition\"\n",
    "    ],\n",
    "    \"ground_truth_category\": [\n",
    "        \"vacuum cleaner\",\n",
    "        \"coffee maker\",\n",
    "        \"smartphone\",\n",
    "        \"drinkware\",\n",
    "        \"headphones\",\n",
    "        \"snack\",\n",
    "        \"exercise equipment\",\n",
    "        \"smart home device\",\n",
    "        \"skincare\",\n",
    "        \"e-reader\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "test_prompt = \"\"\"Classify the following product into a specific consumer product category. \n",
    "Reply in the format: \n",
    "Category: <your category>\n",
    "Reason: <your reasoning based on the product name>\n",
    "Product: \"\"\"\n",
    "\n",
    "llm_model = \"gpt-4.1-nano\"\n",
    "temperature = 0.7\n",
    "max_tokens = 1000\n",
    "df_results = evaluate_product_classification(df_products, llm_model, test_prompt, temperature, max_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0209c1a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            product_name  \\\n",
      "0                 Dyson V11 Torque Drive   \n",
      "1            Keurig K-Supreme Plus SMART   \n",
      "2                      iPhone 15 Pro Max   \n",
      "3             YETI Rambler 20 oz Tumbler   \n",
      "4                        Sony WH-1000XM5   \n",
      "5  Blue Diamond Almonds - Lightly Salted   \n",
      "6                          Peloton Bike+   \n",
      "7              Nest Thermostat (3rd Gen)   \n",
      "8         L'Oréal Paris Revitalift Serum   \n",
      "9    Kindle Paperwhite Signature Edition   \n",
      "\n",
      "                     predicted_category       gold_category  match  \\\n",
      "0                       vacuum cleaners      vacuum cleaner  False   \n",
      "1               small kitchen appliance        coffee maker  False   \n",
      "2                            smartphone          smartphone   True   \n",
      "3                  drinkware / tumblers           drinkware  False   \n",
      "4      headphones / wireless headphones          headphones  False   \n",
      "5                            snack food               snack  False   \n",
      "6                     fitness equipment  exercise equipment  False   \n",
      "7  home automation / smart home devices   smart home device  False   \n",
      "8              skincare / facial serums            skincare  False   \n",
      "9     e-reader / electronic book reader            e-reader  False   \n",
      "\n",
      "   cosine_similarity  \n",
      "0           0.894293  \n",
      "1           0.519339  \n",
      "2           0.999999  \n",
      "3           0.821964  \n",
      "4           0.788420  \n",
      "5           0.900429  \n",
      "6           0.909701  \n",
      "7           0.795692  \n",
      "8           0.736998  \n",
      "9           0.882947  \n"
     ]
    }
   ],
   "source": [
    "df_results.to_csv(\"product_classification_results.csv\", index=False)\n",
    "print(df_results[[\"product_name\", \"predicted_category\", \"gold_category\", \"match\",\"cosine_similarity\"]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
